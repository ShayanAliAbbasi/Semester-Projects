# -*- coding: utf-8 -*-
"""grand-challenge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xLlWwnEHPXWYJcB_-5G3M6_3tVY32J_W
"""

!nvidia-smi

"""#Connecting to google drive"""

from google.colab import drive
drive.mount('/content/drive')

"""# Importing the keras-retinanet library"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/fizyr/keras-retinanet.git

# %cd keras-retinanet/

!git checkout 415b0eb33f6bcd725ffacf81c3b0dcea2a642845

"""#Installing keras-retinanet"""

!pip install .

!python setup.py build_ext --inplace

"""#Installing packages required by keras-retinanet"""

!pip install --upgrade keras
!pip install --upgrade tensorflow-gpu

"""# Importing keras-retinanet dependency packages"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import tensorflow as tf
import pandas as pd
import seaborn as sns
import datetime
from pylab import rcParams
import matplotlib.pyplot as plt
from matplotlib import rc
from pandas.plotting import register_matplotlib_converters
from sklearn.model_selection import train_test_split
import urllib
import os
import csv
import cv2
import time
from PIL import Image

from keras_retinanet import models
from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image
from keras_retinanet.utils.visualization import draw_box, draw_caption
from keras_retinanet.utils.colors import label_color

# %matplotlib inline
# %config InlineBackend.figure_format='retina'

register_matplotlib_converters()
sns.set(style='whitegrid', palette='muted', font_scale=1.5)

rcParams['figure.figsize'] = 22, 10

RANDOM_SEED = 42

np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

os.makedirs("snapshots", exist_ok=True)

!rm -rf ./logs

os.makedirs("logs", exist_ok=True)

"""#Unzipping training data from google drive into colab"""

import gdown

url = 'https://drive.google.com/u/1/uc?export=download&confirm=ALqy&id=1CnYAzZRVEDGK1TycGBb8SnMgyvzeZrie'
output = './train.zip'

gdown.download(url, output, False)

from zipfile import ZipFile

zip_ref = ZipFile('./train.zip', 'r')
zip_ref.extractall()
zip_ref.close()

!rm train.zip

"""#Processing Training Data"""

train_for_actions = 3 #@param ["0", "1", "2", "3"] {type:"raw"}

actions_0 = ['CuttingMesocolon', 'CuttingVasDeferens', 'CuttingSeminalVesicle',
             'CuttingTissue', 'CuttingThread', 'CuttingProstate']
actions_1 = ['PullingVasDeferens', 'PullingSeminalVesicle', 'PullingTissue',
             'PullingProstate', 'PullingBladderNeck']
actions_2 = ['ClippingVasDeferens', 'ClippingTissue', 'ClippingSeminalVesicle',
             'ClippingBladderNeck']
actions_3 = ['SuckingBlood', 'SuckingSmoke', 'BaggingProstate', 
             'BladderNeckDissection', 'BladderAnastomosis']

actions = [actions_0, actions_1, actions_2, actions_3]

class_labels = []
with open("./train/obj.names") as f:
  for line in f:
    line = line.rstrip()
    class_labels.append(line)

from os import listdir
from os.path import join, getsize, splitext, isfile, exists
import pandas as pd
import re

DIR_PATH_1 = "./train/set1/"
DIR_PATH_2 = "./train/set2/"

IMAGE_WIDTH = 1920
IMAGE_HEIGHT = 1080

MAX_PREV_IMG = 1

dataset = dict()

prev_images = []

dataset["image_name"] = []
dataset["x_min"] = []
dataset["y_min"] = []
dataset["x_max"] = []
dataset["y_max"] = []               
dataset["class_name"] = []


dirFiles1 = sorted(listdir(DIR_PATH_1), key=lambda f: int(re.split(r"[._]", f)[-2]))
dirFiles2 = sorted(listdir(DIR_PATH_2), key=lambda f: int(re.split(r"[._]", f)[-2]))

dirFiles = dirFiles1 + dirFiles2

for file in dirFiles:
    
    full_path = join(DIR_PATH_1, file)
    
    if not exists(full_path):

        full_path = join(DIR_PATH_2, file)
    
    if file.endswith('.txt'):
    
        image_name = re.sub(r"txt$", "jpg", full_path)
        
        if (len(prev_images) > 0 and len(prev_images) % (MAX_PREV_IMG + 1) == 0):
            prev_images.pop(0)  

        if getsize(full_path) != 0:
           
            with open(full_path) as f:  
               
                for line in f:
                    
                    for img in prev_images:
                      
                      dataset["image_name"].append(img)
                      dataset["x_min"].append('')
                      dataset["y_min"].append('')
                      dataset["x_max"].append('')
                      dataset["y_max"].append('')                                     
                      dataset["class_name"].append('')

                    prev_images = []

                    line = line.rstrip()
                    line_data = line.split()
                    
                    box_width = int(round(float(line_data[3]) * IMAGE_WIDTH))
                    box_height = int(round(float(line_data[4]) * IMAGE_HEIGHT))
               
                    x_min = int(round(float(line_data[1]) * IMAGE_WIDTH)) - box_width // 2
                    y_min = int(round(float(line_data[2]) * IMAGE_HEIGHT)) - box_height // 2
                    x_max = x_min + box_width
                    y_max = y_min + box_height

                    x_min = 0 if x_min < 0 else x_min
                    y_min = 0 if y_min < 0 else y_min
                    x_max = IMAGE_WIDTH if x_max > IMAGE_WIDTH else x_max
                    y_max = IMAGE_HEIGHT if y_max > IMAGE_HEIGHT else y_max

                    class_name = class_labels[int(line_data[0])]
                    
                    dataset["image_name"].append(image_name)
                    dataset["x_min"].append(x_min)
                    dataset["y_min"].append(y_min)
                    dataset["x_max"].append(x_max)
                    dataset["y_max"].append(y_max)                                     
                    dataset["class_name"].append(class_name)
                    
        else:
           prev_images.append(image_name)

"""#Converting training data to keras-retinanet format"""

from datetime import datetime

df = pd.DataFrame(dataset)

train_actions_df = df[df.class_name.isin(actions[train_for_actions])]
neg_train_actions_df = df[df.class_name == '']
neg_train_actions_df = neg_train_actions_df.sample(frac = min(1.0, len(train_actions_df) / len(neg_train_actions_df)))

train_df = pd.concat([train_actions_df, neg_train_actions_df])

ANNOTATIONS_FILE = 'annotations.csv'
CLASSES_FILE = 'classes.csv'

train_df.to_csv(ANNOTATIONS_FILE, index=False, header=None)

with open(CLASSES_FILE, 'w') as f:
  for i, line in enumerate(actions[train_for_actions]):
    f.write('{},{}\n'.format(line,i))

def show_image_objects(image_row):

  img_path = image_row.image_name

  if image_row.class_name != "":

    box = [
      image_row.x_min, image_row.y_min, image_row.x_max, image_row.y_max
    ]

  image = read_image_bgr(img_path)

  draw = image.copy()
  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)
   
  if image_row.class_name != "":
    draw_box(draw, box, color=(255, 255, 0))
    draw_caption(draw, box=[box[0], box[1]], caption=image_row.class_name)

  plt.axis('off')
  plt.imshow(draw)
  plt.show()

# show_image_objects(train_df.iloc[0])

"""#Loading Validation Data"""

import gdown

url = 'https://drive.google.com/a/lgu.edu.pk/uc?id=1cYojEB4hJclmbnqy42R5lSpSDR5Ca7S_&export=download'
output = './val.zip'

gdown.download(url, output, False)

from zipfile import ZipFile

zip_ref = ZipFile('./val.zip', 'r')
zip_ref.extractall()
zip_ref.close()

!rm val.zip

class_labels = []

with open("./val/obj.names") as f:
    for line in f:
        line = line.rstrip()
        class_labels.append(line)

from os import listdir
from os.path import join, getsize, splitext, isfile
import pandas as pd
import re

DIR_PATH = "./val/obj/"

IMAGE_WIDTH = 1920
IMAGE_HEIGHT = 1080

dataset = dict()

dataset["image_name"] = []
dataset["x_min"] = []
dataset["y_min"] = []
dataset["x_max"] = []
dataset["y_max"] = []
dataset["class_name"] = []

dirFiles = sorted(listdir(DIR_PATH), key=lambda f: int(re.split(r"[._]", f)[-2]))

for file in dirFiles:
    
    full_path = join(DIR_PATH, file)
    
    if isfile(full_path) and file.endswith('.txt'):
        
        if (getsize(full_path) > 0):
          
          with open(full_path) as f:
              
              for line in f:
                  
                  line = line.rstrip()
                  line_data = line.split()

                  image_name = DIR_PATH + splitext(file)[0] + '.jpg'
                  
                  box_width = int(round(float(line_data[3]) * IMAGE_WIDTH))
                  box_height = int(round(float(line_data[4]) * IMAGE_HEIGHT))
                
                  x_min = int(round(float(line_data[1]) * IMAGE_WIDTH)) - box_width // 2
                  y_min = int(round(float(line_data[2]) * IMAGE_HEIGHT)) - box_height // 2
                  x_max = x_min + box_width
                  y_max = y_min + box_height
                  
                  x_min = 0 if x_min < 0 else x_min
                  y_min = 0 if y_min < 0 else y_min
                  x_max = IMAGE_WIDTH if x_max > IMAGE_WIDTH else x_max
                  y_max = IMAGE_HEIGHT if y_max > IMAGE_HEIGHT else y_max

                  class_name = class_labels[int(line_data[0])]
                  
                  dataset["image_name"].append(image_name)
                  dataset["x_min"].append(x_min)
                  dataset["y_min"].append(y_min)
                  dataset["x_max"].append(x_max)
                  dataset["y_max"].append(y_max)                                     
                  dataset["class_name"].append(class_name)
      
        else:

          image_name = DIR_PATH + splitext(file)[0] + '.jpg'
          dataset["image_name"].append(image_name)
          dataset["x_min"].append('')
          dataset["y_min"].append('')
          dataset["x_max"].append('')
          dataset["y_max"].append('')                                     
          dataset["class_name"].append('')

from datetime import datetime

df = pd.DataFrame(dataset)

val_actions_df = df[df.class_name.isin(actions[train_for_actions])]

neg_val_actions_df = df[df.class_name == '']
neg_val_actions_df = neg_val_actions_df.sample(frac = min(0.5, len(val_actions_df) / len(neg_val_actions_df)))

val_df = pd.concat([val_actions_df, neg_val_actions_df]).sample(frac = 0.35)

ANNOTATIONS_FILE = 'val_annotations.csv'

val_df.to_csv(ANNOTATIONS_FILE, index=False, header=None)

"""# Training"""

from os import makedirs

backbone = 'resnet101' #@param ["resnet50", "resnet101", "resnet152"]

snapshot_path = "../drive/My Drive/Colab Notebooks/snapshots/{}/{}".format(backbone, train_for_actions)

makedirs(snapshot_path, exist_ok=True)

#snapshot_file = os.path.join(snapshot_path, sorted(os.listdir(snapshot_path), reverse=True)[0])

# !cp "{snapshot_file}" ./snapshots

# snapshot_file = 'snapshots/' + snapshot_file.split('/')[-1]

import re
# recent_epoch = int(re.split(r'[._]', snapshot_file)[-2])

# print(snapshot_file)
# print(recent_epoch)

# --weights "{snapshot_file}"
# --freeze-backbone \
# --initial-epoch {recent_epoch} \
# --compute-val-loss \

!keras_retinanet/bin/train.py \
  --random-transform \
  --freeze-backbone \
  --backbone "{backbone}" \
  --snapshot "{snapshot_file}" \
  --weighted-average \
  --snapshot-path "{snapshot_path}" \
  --batch-size 2 \
  --steps 2000 \
  --image-min-side 800 \
  --image-max-side 1422 \
  --compute-val-loss \
  --epochs 8 \
  csv annotations.csv classes.csv --val-annotations val_annotations.csv

"""# Loading the trained model"""

#snapshot_file = os.path.join(snapshot_path, sorted(os.listdir(snapshot_path), reverse=True)[0])
#!cp "{snapshot_file}" ./snapshots

model_path = os.path.join(snapshot_path, sorted(os.listdir(snapshot_path), reverse=True)[0])
print(model_path)

model = models.load_model(model_path, backbone_name=backbone)
model = models.convert_model(model)

labels_to_names = pd.read_csv(CLASSES_FILE, header=None).T.loc[0].to_dict()

"""# Predictions"""

def predict(image):
  image = preprocess_image(image.copy())
  image, scale = resize_image(image, min_side = 288, max_side = 512)

  boxes, scores, labels = model.predict_on_batch(
    np.expand_dims(image, axis=0)
  )

  boxes /= scale

  return boxes, scores, labels

THRES_SCORE = 0.5

def draw_detections(image, boxes, scores, labels):
  for box, score, label in zip(boxes[0], scores[0], labels[0]):
    if score < THRES_SCORE:
        break

    color = label_color(label)

    b = box.astype(int)
    draw_box(image, b, color=color)

    caption = "{} {:.3f}".format(labels_to_names[label], score)
    draw_caption(image, b, caption)

def show_detected_objects(image_row):
  img_path = image_row.image_name
  
  image = read_image_bgr(img_path)

  boxes, scores, labels = predict(image)

  draw = image.copy()
  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)

  all_boxes = val_df.loc[val_df['image_name'] == img_path]
  for index, row in all_boxes.iterrows():
    true_box = [row.x_min, row.y_min, row.x_max, row.y_max]
    draw_box(draw, true_box, color=(255, 255, 0))
    caption = "{}".format(row.class_name)
    draw_caption(draw, [row.x_min, row.y_min + row.y_max - row.y_min, row.x_max, row.y_max ], caption)

  draw_detections(draw, boxes, scores, labels)

  plt.axis('off')
  plt.imshow(draw)
  plt.show()

show_detected_objects(val_df.iloc[0])

#--max-detections 5 \
!/content/keras-retinanet/keras_retinanet/bin/evaluate.py \
  --convert-model \
  --save-path '/content/keras-retinanet/images' \
  --backbone 'resnet152' \
  --image-min-side 288 \
  --image-max-side 512 \
  --score-threshold 0.4 \
  --iou-threshold 0.5 \
  csv val_annotations.csv classes.csv '/content/drive/My Drive/Colab Notebooks/snapshots/resnet152_csv_31.h5'

!zip -r ./eval.zip ./logs

!ps -aux|grep python

#!kill -9 120
!rm -r ./logs

"""# Loading Test Data"""

import gdown

url = 'https://drive.google.com/a/lgu.edu.pk/uc?id=1gho-oGzUbNgnZmBZ2GDKWWOcs1VI-z0O&export=download'
output = './test.zip'

gdown.download(url, output, False)

from zipfile import ZipFile

zip_ref = ZipFile('./test.zip', 'r')
zip_ref.extractall()
zip_ref.close()

!rm test.zip

def generate_submission_file( images_paths, parent_directory, dest_file_path='submission.txt', score_threshold=0.05, min_side=288, max_side=512):

  image_min_side = min_side
  image_max_side = max_side

  with open(dest_file_path, 'w') as submission_file:

    for image_path in images_paths:
      
      image = read_image_bgr(parent_directory + "/" + image_path)
      image = preprocess_image(image.copy())
      image, scale = resize_image(image, min_side = image_min_side, max_side = image_max_side)

      boxes, scores, labels = model.predict_on_batch(
        np.expand_dims(image, axis=0)
      )

      for box, score, label in zip(boxes[0], scores[0], labels[0]):
        
        if score < score_threshold:
            break

        box[0] /= image_max_side
        box[1] /= image_min_side
        box[2] /= image_max_side
        box[3] /= image_min_side

        submission_file.write(f"{image_path} {box[0]:.6f} {box[1]:.6f} " +
                              f"{box[2]:.6f} {box[3]:.6f} {score:.6f} {label}\n")

from os import listdir
import re

DIR_PATH = "./test"

test_images_paths = sorted(listdir(DIR_PATH), key=lambda f: int(re.split(r"[._]", f)[-2]))

generate_submission_file(test_images_paths, DIR_PATH)

show_detected_objects(DIR_PATH + "/" + test_images_paths[0], score_thres=0.3, min_side=232, max_side=512)